# ODIN v7.0 - Multi-Agent Orchestration for Reliable AI Development

[![CI](https://github.com/Krigsexe/AI-Context-Engineering/workflows/CI/badge.svg)](https://github.com/Krigsexe/AI-Context-Engineering/actions)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**ODIN** (Orchestrated Development Intelligence Network) is a multi-agent framework for reliable AI-assisted development with anti-hallucination features, provider-agnostic LLM support, and complete user sovereignty.

## ğŸ¯ Key Features

- **Provider Agnostic**: Use ANY LLM provider - Ollama, Anthropic, OpenAI, Google, Groq, Together, DeepSeek, HuggingFace, or your own
- **Multi-Agent Architecture**: 10 specialized agents for different tasks
- **Anti-Hallucination**: 5-level confidence framework with oracle verification
- **Checkpoint/Rollback**: Full state preservation with semantic integrity hashing
- **100% Local Option**: Run entirely offline with Ollama

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Request                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      IntakeAgent                                 â”‚
â”‚              (Classify, Extract Context, Route)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DevAgent      â”‚ â”‚  ReviewAgent    â”‚ â”‚  SecurityAgent  â”‚
â”‚   (Generate,    â”‚ â”‚  (Review,       â”‚ â”‚  (Scan, Check   â”‚
â”‚    Modify,      â”‚ â”‚   Quality)      â”‚ â”‚   Secrets)      â”‚
â”‚    Debug)       â”‚ â”‚                 â”‚ â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚                    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     OracleCodeAgent                              â”‚
â”‚            (Execute, Verify, Validate - AXIOM Confidence)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/Krigsexe/AI-Context-Engineering.git
cd AI-Context-Engineering

# Install Python package
pip install -e ".[dev]"

# Or use one-click install
./install.sh
```

### Configure LLM Provider

**Option 1: Local with Ollama (Recommended for privacy)**
```bash
# Install Ollama (https://ollama.ai)
ollama pull qwen2.5:7b
```

**Option 2: Cloud Provider**
```bash
# Set your preferred provider's API key
export ANTHROPIC_API_KEY="your-key"  # or
export OPENAI_API_KEY="your-key"     # or
export GROQ_API_KEY="your-key"       # etc.
```

### Basic Usage

```python
import asyncio
from agents import LLMClient, DevAgent, InMemoryStateStore

async def main():
    # Initialize
    client = LLMClient()  # Auto-detects available providers
    store = InMemoryStateStore()
    dev = DevAgent(llm_client=client, state_store=store)

    await dev.start()

    # Generate code
    result = await dev.run_task(
        "generate_code",
        {
            "requirements": "Create a function to calculate fibonacci",
            "language": "python",
        }
    )

    print(f"Success: {result.success}")
    print(f"Confidence: {result.confidence.name}")
    print(f"Code: {result.data['code']}")

    await dev.stop()

asyncio.run(main())
```

### CLI Usage

```bash
# List available agents
odin-agent list

# Run a task
odin-agent task dev generate_code -i '{"requirements": "Hello World function", "language": "python"}'

# Check available providers
odin-agent providers

# System health check
odin-agent health
```

## ğŸ“¦ Available Agents

| Agent | Type | Description |
|-------|------|-------------|
| `IntakeAgent` | Cognitive | Request analysis, classification, routing |
| `DevAgent` | Cognitive | Code generation, modification, debugging |
| `RetrievalAgent` | Cognitive | Context gathering, codebase search |
| `ReviewAgent` | Cognitive | Code review, quality scoring |
| `ArchitectAgent` | Cognitive | Architecture decisions, design patterns |
| `OracleCodeAgent` | Oracle | Code execution verification (AXIOM confidence) |
| `TestAgent` | Execution | Test generation and execution |
| `SecurityAgent` | Execution | OWASP scanning, secret detection |
| `CheckpointAgent` | System | State preservation, rollback |
| `AuditAgent` | System | Activity logging, audit trails |

## ğŸ”Œ Supported LLM Providers

### Local (No API Key Required)
- **Ollama** - Default, recommended for privacy
- **vLLM** - High-performance serving
- **llama.cpp** - CPU inference
- **LocalAI** - OpenAI-compatible local server

### Cloud
- **Anthropic** (Claude)
- **OpenAI** (GPT-4, GPT-3.5)
- **Google** (Gemini)
- **Groq** (Fast inference)
- **Together.ai**
- **DeepSeek**
- **HuggingFace**
- **And more...**

## ğŸ›¡ï¸ Confidence Framework

ODIN uses a 5-level confidence system:

| Level | Value | Description |
|-------|-------|-------------|
| **AXIOM** | 100% | Deterministic/verified (Oracle results) |
| **HIGH** | 95%+ | Very confident, verified |
| **MODERATE** | 70-95% | Reasonably confident |
| **UNCERTAIN** | 40-70% | Needs verification |
| **UNKNOWN** | <40% | Should not proceed |

## ğŸ“ Project Structure

```
AI-Context-Engineering/
â”œâ”€â”€ agents/                    # Python agent framework
â”‚   â”œâ”€â”€ cognitive/            # Cognitive layer agents
â”‚   â”œâ”€â”€ oracle/               # Oracle verification agents
â”‚   â”œâ”€â”€ execution/            # Execution agents
â”‚   â”œâ”€â”€ system/               # System management agents
â”‚   â””â”€â”€ shared/               # Shared infrastructure
â”‚       â”œâ”€â”€ providers/        # LLM provider implementations
â”‚       â”œâ”€â”€ llm_client.py     # Universal LLM client
â”‚       â”œâ”€â”€ message_bus.py    # Redis Streams messaging
â”‚       â””â”€â”€ state_store.py    # PostgreSQL state management
â”œâ”€â”€ orchestrator/             # Go orchestrator
â”œâ”€â”€ api/                      # TypeScript REST/WebSocket API
â”œâ”€â”€ tests/                    # Unit and integration tests
â”œâ”€â”€ examples/                 # Usage examples
â”œâ”€â”€ docs/                     # Documentation
â””â”€â”€ docker-compose.yml        # Multi-service orchestration
```

## ğŸ³ Docker Deployment

```bash
# Start all services
docker compose up -d

# Start with local LLM (Ollama)
docker compose --profile local-llm up -d

# Start with knowledge graph (Neo4j)
docker compose --profile knowledge-graph up -d
```

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=agents --cov-report=html

# Run specific test file
pytest tests/unit/test_integrity.py -v
```

## ğŸ“– Documentation

- [Architecture Overview](docs/ARCHITECTURE.md)
- [LLM Providers Guide](docs/LLM_PROVIDERS.md)
- [Configuration Reference](docs/USER_CONFIGURATION.md)
- [Vision & Philosophy](docs/VISION.md)

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting PRs.

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a PR

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.
<div align="center">

[![Visitors Badge](https://api.visitorbadge.io/api/VisitorHit?user=Krigsexe&repo=AI-Context-Engineering&countColor=%237B1E7A)](https://github.com/Krigsexe/AI-Context-Engineering)

# ODIN v7.0 - Context Engineering Framework

**Making Large Language Models Reliable for Production Development**

</div>

---

## Table des MatiÃ¨res

- [AperÃ§u du Projet](#aperÃ§u-du-projet)
- [Le ProblÃ¨me](#le-problÃ¨me)
- [La Solution ODIN](#la-solution-odin)
- [Principes ClÃ©s](#principes-clÃ©s)
- [Architecture](#architecture)
- [Exemple Concret](#exemple-concret)
- [Analyse Comparative](#analyse-comparative)
- [Stack Technique](#stack-technique)
- [Installation](#installation)
- [Fondations Recherche](#fondations-recherche)
- [Statut du Projet](#statut-du-projet)
- [Documentation](#documentation)
- [Philosophie](#philosophie)
- [Contribution](#contribution)
- [Licence & Attribution](#licence--attribution)

---

## AperÃ§u du Projet

### ODIN v7.0 - Context Engineering Framework
Making Large Language Models Reliable for Production Development

ODIN est un systÃ¨me meta-cognitif conÃ§u pour augmenter les Grands ModÃ¨les de Langage (LLMs) avec validation externe, raisonnement structurÃ© et vÃ©rification systÃ©matique. PlutÃ´t que de remplacer ou rÃ©entraÃ®ner les LLMs, ODIN ajoute des couches intelligentes autour d'eux pour Ã©liminer les hallucinations, garantir la traÃ§abilitÃ© et permettre le dÃ©veloppement autonome fiable.

**Statut Actuel : Recherche et DÃ©veloppement (Novembre 2025) - ANALOGIE.md contient la thÃ©orie fondationnelle.**

---

## Le ProblÃ¨me

### Why Standard LLMs Are Unreliable for Production / Pourquoi les LLMs Standard ne sont pas Fiables en Production

Large Language Models are statistical predictors, not knowledge systems. They excel at pattern matching but fail at reliability:

Les Grands ModÃ¨les de Langage sont des prÃ©dicteurs statistiques, pas des systÃ¨mes de connaissance. Ils excellent au pattern matching mais Ã©chouent sur la fiabilitÃ© :

- **Hallucinations are inherent** - LLMs predict the next token probabilistically, not factually. When confident they don't know, they invent plausible-sounding answers.
- **Confusion between probability and truth** - P(response | context) â‰  P(response is true). A model can be 95% confident in something completely false.
- **No mechanism to say "I don't know"** - Training incentivizes producing text over admitting uncertainty.
- **Context overflow cascades** - Long tasks cause models to lose track of goals, constraints, and earlier decisions.
- **No self-correction** - Models cannot verify their own outputs or learn from failures without external feedback.

- **Les hallucinations sont inhÃ©rentes** - Les LLMs prÃ©disent le prochain token probabilistiquement, pas factuellement. Quand ils croient ne pas savoir, ils inventent des rÃ©ponses plausibles.
- **Confusion entre probabilitÃ© et vÃ©ritÃ©** - P(rÃ©ponse | contexte) â‰  P(rÃ©ponse est vraie). Un modÃ¨le peut Ãªtre 95% confiant en quelque chose complÃ¨tement faux.
- **Aucun mÃ©canisme pour dire Â« je ne sais pas Â»** - L'entraÃ®nement incite Ã  produire du texte plutÃ´t qu'Ã  avouer l'incertitude.
- **DÃ©bordement de contexte en cascade** - Les tÃ¢ches longues font perdre au modÃ¨le le fil des objectifs, contraintes et dÃ©cisions antÃ©rieures.
- **Pas d'auto-correction** - Les modÃ¨les ne peuvent vÃ©rifier leurs propres sorties ou apprendre des Ã©checs sans feedback externe.

### Tableau des Impacts

| ProblÃ¨me | Impact | SÃ©vÃ©ritÃ© |
|----------|--------|----------|
| Hallucinations / Hallucinations | Faits incorrects prÃ©sentÃ©s comme vrais / Incorrect facts presented as truth | Critique / Critical |
| RÃ©gressions / Regression | Mises Ã  jour cassent les fonctionnalitÃ©s / Updates break previously working features | Ã‰levÃ©e / High |
| Perte de contexte / Context loss | Objectifs oubliÃ©s dans les tÃ¢ches longues / Goals forgotten in long tasks | Ã‰levÃ©e / High |
| Boucles dangereuses / Dangerous loops | ExÃ©cution autonome sans validation / Autonomous execution without validation | Critique / Critical |
| Pas de responsabilitÃ© / No accountability | Aucune trace du raisonnement ou des sources / No trace of reasoning or sources | Ã‰levÃ©e / High |

---

## La Solution ODIN

ODIN augmente les LLMs avec un systÃ¨me meta-cognitif disciplinaire. Il ne remplace PAS le LLM lui-mÃªme â€” il ajoute des couches de validation avant, pendant et aprÃ¨s la gÃ©nÃ©ration.

**The ODIN Solution:** ODIN augments LLMs with a disciplinary meta-cognitive system. It does NOT replace the LLM itselfâ€”instead, it adds validation layers before, during, and after generation.

---

## Principes ClÃ©s

### Three Key Principles / Trois Principes ClÃ©s

**1. Complement, Don't Replace / ComplÃ©mentaire, Pas Remplacement**
- The LLM's transformer architecture remains untouched. ODIN adds agents and oracles around it.
- L'architecture transformer du LLM reste inchangÃ©e. ODIN ajoute des agents et des oracles autour.

**2. Multi-Layer Validation / Validation Multi-Couche**
- Every output passes through independent verification: code execution, security scanning, fact-checking, and human approval.
- Chaque sortie passe par une vÃ©rification indÃ©pendante : exÃ©cution de code, scanning de sÃ©curitÃ©, vÃ©rification des faits et approbation humaine.

**3. Structured Uncertainty / Incertitude StructurÃ©e**
- Instead of binary right/wrong, ODIN computes confidence levels (0-100%) and refuses to answer when below thresholds.
- Au lieu d'un binaire juste/faux, ODIN calcule des niveaux de confiance (0-100%) et refuse de rÃ©pondre en dessous des seuils.

---

## Architecture

### Architecture Overview / Vue d'Ensemble de l'Architecture

```text
LAYER 1: PRE-PROCESSING / COUCHE 1 : PRE-TRAITEMENT
(Context Preparation / PrÃ©paration du Contexte)
â”œâ”€ Retrieval Agent / Agent RÃ©cupÃ©ration â†’ Search verified knowledge / Recherche de connaissance vÃ©rifiÃ©e
â”œâ”€ Verification Agent / Agent VÃ©rification â†’ Cross-check multiple sources / Cross-check de sources multiples
â”œâ”€ Knowledge Graph / Graphe de Connaissance â†’ Structured fact lookup / Recherche structurÃ©e de faits
â””â”€ Oracle Temporal / Oracle Temporel â†’ Validate information freshness / Validation de la fraÃ®cheur d'info

        â†“ (Prepared context / Contexte prÃ©parÃ© : high confidence / haute confiance, sourced / sourcÃ©)

LAYER 2: LLM GENERATION / COUCHE 2 : GÃ‰NÃ‰RATION LLM
(Qwen 2.5 7B - Unchanged / Qwen 2.5 7B - InchangÃ©)
â”œâ”€ Chain-of-Thought Prompting / Chain-of-Thought Prompting â†’ Guided reasoning / Raisonnement guidÃ©
â”œâ”€ Context Injection / Injection de Contexte â†’ Best practices included / Meilleures pratiques incluses
â””â”€ Temperature Control / ContrÃ´le TempÃ©rature â†’ Deterministic output / Sortie dÃ©terministe

        â†“ (Raw LLM response / RÃ©ponse brute du LLM)

LAYER 3: POST-VALIDATION / COUCHE 3 : POST-VALIDATION
(Output Verification / VÃ©rification de Sortie)
â”œâ”€ Oracle Code Execution / Oracle ExÃ©cution Code â†’ Run and test / ExÃ©cution et tests
â”œâ”€ Oracle Security Scan / Oracle Security Scan â†’ SAST/DAST checks / Scanning SAST/DAST
â”œâ”€ Oracle Consensus / Oracle Consensus â†’ Multi-model agreement / Accord multi-modÃ¨les
â”œâ”€ Critique Agent / Agent Critique â†’ Red team challenge / Red team challenge
â””â”€ Confidence Calibration / Calibration de Confiance â†’ Truth likelihood score / Score de vraisemblance

        â†“

CHECKPOINT & ROLLBACK
â””â”€ Every decision logged and reversible / Chaque dÃ©cision enregistrÃ©e et rÃ©versible
```

---

## Multi-Agent Orchestration

ODIN coordinates 30+ specialized agents / ODIN coordonne plus de 30 agents spÃ©cialisÃ©s :

```text
Retrieval & Knowledge / RÃ©cupÃ©ration et Connaissance
â”œâ”€ research_web - Verified external information / Information externe vÃ©rifiÃ©e
â”œâ”€ research_codebase - Codebase analysis and context / Analyse et contexte codebase
â””â”€ indexation - Vector embedding and semantic search / Embedding vectoriel et recherche sÃ©mantique

Development / DÃ©veloppement
â”œâ”€ dev - Code generation / GÃ©nÃ©ration de code
â”œâ”€ refacto - Code improvement / AmÃ©lioration de code
â””â”€ tests - Test generation and execution / GÃ©nÃ©ration et exÃ©cution de tests

Verification / VÃ©rification
â”œâ”€ verif_syntax - Linting and parsing / Linting et parsing
â”œâ”€ verif_security - Security scanning (SAST) / Scanning de sÃ©curitÃ© (SAST)
â”œâ”€ verif_performance - Profiling and optimization / Profiling et optimisation
â”œâ”€ code_review - Style and pattern checking / VÃ©rification style et patterns
â””â”€ pertinence - Goal alignment verification / VÃ©rification d'alignement aux objectifs

Orchestration
â”œâ”€ approbation - Human validation gate / Porte de validation humaine
â”œâ”€ mcp - Checkpoint management and rollback / Gestion des checkpoints et rollback
â”œâ”€ apprentissage - Feedback loop and learning / Boucle de feedback et apprentissage
â”œâ”€ critique - Adversarial red team / Red team adversariel
â””â”€ oracle_* - External validators (code, KG, temporal, consensus) / Validateurs externes

Support
â”œâ”€ architecture - Design decisions / DÃ©cisions de design
â”œâ”€ documentation - Doc generation / GÃ©nÃ©ration de doc
â”œâ”€ build - Build orchestration / Orchestration de build
â”œâ”€ deploy - Deployment management / Gestion du dÃ©ploiement
â””â”€ monitoring - Runtime health / SantÃ© runtime
```

---

## Exemple Concret

### Before vs After: Concrete Example / Avant vs AprÃ¨s : Exemple Concret

**The Problem: Code Generation / Le ProblÃ¨me : GÃ©nÃ©ration de Code**

```
User: "Create a FastAPI endpoint with JWT authentication"
User : "CrÃ©e un endpoint FastAPI avec authentification JWT"
```

#### âŒ STANDARD LLM (Qwen alone / Qwen seul)

```
â”œâ”€ Generates code quickly / GÃ©nÃ¨re du code rapidement
â”œâ”€ May use outdated JWT algorithms / Peut utiliser des algorithmes JWT obsolÃ¨tes
â”œâ”€ Hardcodes secrets in code / Hardcode les secrets dans le code
â”œâ”€ Doesn't add rate limiting / N'ajoute pas de rate limiting
â”œâ”€ No security scanning / Pas de scanning de sÃ©curitÃ©
â””â”€ Result: 20-30% hallucination rate / RÃ©sultat : 20-30% de taux d'hallucination
```

#### âœ… THE ODIN SOLUTION / LA SOLUTION ODIN

```
PRE-PROCESSING / PRE-TRAITEMENT
  â”œâ”€ Retrieval â†’ "FastAPI JWT examples" + "JWT 2024 RFC" / "FastAPI JWT exemples" + "JWT 2024 RFC"
  â”œâ”€ Verification â†’ Cross-check 3 sources (JWT specs agree) / Cross-check 3 sources (RFC JWT en accord)
  â”œâ”€ Knowledge Graph â†’ Confirms RS256 is current standard / Confirme que RS256 est le standard courant
  â””â”€ Temporal Oracle â†’ "RFC updated 2024, info valid" / "RFC mis Ã  jour 2024, info valide"

PROMPTING (To Qwen / Ã€ Qwen)
  "Generate FastAPI code using:
   - JWT RS256 (asymmetric, not HS256)
   - Environment variables for secrets
   - bcrypt password hashing
   - Rate limiting per user
   - Full docstrings"
   
  "GÃ©nÃ¨re du code FastAPI en utilisant :
   - JWT RS256 (asymÃ©trique, pas HS256)
   - Variables d'environnement pour les secrets
   - Hash bcrypt pour les mots de passe
   - Rate limiting par utilisateur
   - Docstrings complets"

QWEN GENERATES / QWEN GÃ‰NÃˆRE
  - Code with best practices injected via context / Code avec meilleures pratiques injectÃ©es via contexte
  - Higher confidence due to quality input / Confiance plus Ã©levÃ©e grÃ¢ce Ã  meilleure entrÃ©e

POST-VALIDATION
  â”œâ”€ Syntax check (pylint) â†’ PASS / VÃ©rification syntaxe (pylint) â†’ OK
  â”œâ”€ Type check (mypy) â†’ PASS / VÃ©rification type (mypy) â†’ OK
  â”œâ”€ Security scan (bandit + semgrep) â†’ PASS (no hardcoded secrets) / Scanning sÃ©curitÃ© (bandit + semgrep) â†’ OK (pas de secrets hardcodÃ©s)
  â”œâ”€ Unit tests (generated + executed) â†’ PASS / Tests unitaires (gÃ©nÃ©rÃ©s + exÃ©cutÃ©s) â†’ OK
  â”œâ”€ Red team challenge â†’ "Handles expired tokens? Yes. Rate limiting works? Yes." / "GÃ¨re les tokens expirÃ©s ? Oui. Rate limiting fonctionne ? Oui."
  â”œâ”€ Oracle consensus (3 models agree) â†’ PASS / Oracle consensus (3 modÃ¨les en accord) â†’ OK
  â””â”€ Human approval / Approbation humaine â†’ APPROVED / APPROUVÃ‰

RESULT / RÃ‰SULTAT
  Code generated, validated by 7 independent checks, rollback-ready
  Code gÃ©nÃ©rÃ©, validÃ© par 7 vÃ©rifications indÃ©pendantes, prÃªt pour rollback
  Result: 1-3% hallucination rate / RÃ©sultat : 1-3% de taux d'hallucination
```

---

## Analyse Comparative

### Comparative Analysis / Analyse Comparative

| Aspect | LLM Alone / LLM Seul | LLM + ODIN |
|--------|---------------------|-----------|
| Hallucination Rate / Taux Hallucination | 20-30% | 1-3% |
| Implementation Cost / CoÃ»t ImplÃ©mentation | Baseline | +design systÃ¨me |
| Time to Reliability / Temps FiabilitÃ© | Never (no verification) / Jamais (pas vÃ©rif) | Immediate / ImmÃ©diat |
| Model Changes Required / Changements ModÃ¨le | None / Aucun | None / Aucun |
| Applicability / ApplicabilitÃ© | Model-specific / Model-spÃ©cifique | All LLMs / Tous les LLMs |
| Source Attribution / Attribution Source | Not tracked / Non tracÃ©e | 100% traced / 100% tracÃ©e |
| Rollback Capability / CapacitÃ© Rollback | Not possible / Impossible | Automatic / Automatique |
| Confidence Calibration / Calibration Confiance | None / Aucune | Per-claim scoring / Score par claim |
| Security Validation / Validation SÃ©curitÃ© | Manual/absent / Manuel/absent | Automatic scanning / Scanning automatique |

---

## Insight SystÃ¨me vs ModÃ¨le

### Key Insight: System vs Model / Insight ClÃ© : SystÃ¨me vs ModÃ¨le

**The Problem IS NOT Qwen 7B Itself / Le ProblÃ¨me N'EST PAS Qwen 7B Lui-mÃªme**

A single LLM, unsupervised, is like asking an expert to answer without checking sources, without a team, without process. Inevitably: hallucinations.
Un LLM seul, sans supervision, c'est comme demander Ã  un expert de rÃ©pondre sans vÃ©rifier ses sources, sans Ã©quipe, sans processus. InÃ©vitablement : hallucinations.

**With ODIN / Avec ODIN**

- Qwen + Retrieval = Expert with sources / Expert avec ses sources
- Qwen + Knowledge Graph = Expert with domain structure / Expert avec domaine structurÃ©
- Qwen + Oracle Checks = Expert with tests / Expert avec ses tests
- Qwen + Critique Agent = Expert reviewed by peer / Expert revu par un pair
- Qwen + Feedback Loop = Expert who learns / Expert qui apprend

**The LLM's atomic structure (transformer, attention, weights) remains UNCHANGED. What changes is the disciplinary system around it.**
**L'architecture atomique du LLM (transformer, attention, poids) reste INCHANGÃ‰E. Ce qui change, c'est le systÃ¨me disciplinaire autour.**

---

## Stack Technique

### Technical Stack / Stack Technique

| Component / Composant | Technology / Technologie | Why / Pourquoi |
|----------------------|-------------------------|----------------|
| Orchestrator / Orchestrator | Go 1.21+ | Concurrency, performance, single binary / Concurrence, perf, binaire unique |
| Agents / Agents | Python 3.11+ | ML ecosystem, RAG native, embeddings / Ã‰cosystÃ¨me ML, RAG natif, embeddings |
| API / API | TypeScript/Node.js | Async, modern, maintainable / Async, moderne, maintenable |
| CLI / CLI | Go + Cobra | Native binary, cross-platform / Binaire natif, cross-plateforme |
| Message Bus / Message Bus | Redis Streams | Sub-millisecond latency, exactly-once semantics / Latence <1ms, exactly-once semantics |
| State Store / State Store | PostgreSQL 16 | ACID transactions, complex queries / Transactions ACID, requÃªtes complexes |
| Vector DB / Vector DB | FAISS | Local embeddings, semantic search / Embeddings locaux, recherche sÃ©mantique |
| LLM Server / LLM Server | Ollama | Local models, GPU support, model swapping / ModÃ¨les locaux, support GPU, swap modÃ¨les |
| Container / Container | Docker + Compose | Reproducibility, isolation, one-click deployment / ReproductibilitÃ©, isolation, dÃ©ploiement one-click |
| Default LLM / LLM DÃ©faut | Qwen 2.5 7B | Code + reasoning balance, open source / Ã‰quilibre code+raisonnement, open source |

---

## Installation

### Installation (One-Click)

```bash
git clone https://github.com/krigsexe/ai-context-engineering 
cd ai-context-engineering

# Verify Docker and Docker Compose / VÃ©rifier Docker et Docker Compose
docker --version
docker compose --version

# Install ODIN / Installer ODIN
./install.sh
```

**The script will / Le script va :**

- Download LLM models locally (Qwen 2.5 7B default) / TÃ©lÃ©charger les modÃ¨les LLM localement (Qwen 2.5 7B par dÃ©faut)
- Start PostgreSQL, Redis, Ollama services / DÃ©marrer les services PostgreSQL, Redis, Ollama
- Build and deploy orchestrator, agents, and API / Builder et dÃ©ployer orchestrator, agents et API
- Run health checks / Lancer les health checks

**Access / AccÃ¨s :**

- API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- CLI: docker compose run --rm cli odin status

---

## Fondations Recherche

### Research Foundation / Fondations Scientifiques

This project is grounded in peer-reviewed research / Ce projet s'appuie sur la recherche peer-reviewed :

**Hallucinations and Uncertainty / Hallucinations et Incertitude**

- arxiv: Temperature and Hallucinations / arxiv: TempÃ©rature et Hallucinations
- arxiv: RLHF and Evaluation Misalignment / arxiv: RLHF et Misalignment d'Ã‰valuation
- Kapa AI: Hallucination Causes / Kapa AI: Causes des Hallucinations

**Multi-Agent Systems / SystÃ¨mes Multi-Agents**

- LangGraph (Anthropic) / LangGraph (Anthropic)
- AutoGen (Microsoft Research) / AutoGen (Microsoft Research)
- CrewAI patterns / Patterns CrewAI

**Constitutional AI / Constitutional AI**

- Anthropic: Constitutional AI / Anthropic: Constitutional AI
- Prompt engineering techniques (27% to <5% hallucination reduction) / Techniques prompt engineering (27% Ã  <5% rÃ©duction hallucinations)

**For detailed reasoning / Pour un raisonnement dÃ©taillÃ© :** See docs/ANALOGIE.md and docs/ARCHITECTURE.md / Voir docs/ANALOGIE.md et docs/ARCHITECTURE.md

---

## Statut du Projet

### Project Status / Statut du Projet

**Phase 1: Foundation (Current - R&D) / Phase 1 : Fondation (Actuel - R&D)**

- Core architecture design / Design d'architecture
- Multi-agent framework / Framework multi-agents
- Knowledge graph integration / IntÃ©gration graphe de connaissance
- Docker orchestration / Orchestration Docker

**Phase 2: Integration (Planned) / Phase 2 : IntÃ©gration (PrÃ©vu)**

- CLI and API completion / ComplÃ©tude CLI et API
- IDE plugins (VS Code, JetBrains) / Plugins IDE (VS Code, JetBrains)
- Advanced RAG features / FonctionnalitÃ©s RAG avancÃ©es

**Phase 3: Production (Planned) / Phase 3 : Production (PrÃ©vu)**

- Auto-rollback refinement / Affinement auto-rollback
- Community contributions / Contributions communautÃ©
- Performance optimization / Optimisation performance

---

## Documentation

- **ANALOGIE.md** - Philosophical foundations and mental models / Fondations philosophiques et modÃ¨les mentaux
- **ARCHITECTURE.md** - Technical deep-dive / Deep-dive technique
- **AGENTS.md** - Role of each agent / RÃ´le de chaque agent
- **API.md** - REST API reference / RÃ©fÃ©rence API REST
- **CLI.md** - Command-line reference / RÃ©fÃ©rence ligne de commande
- **CONTRIBUTING.md** - How to contribute / Comment contribuer

---

## Philosophie

### Philosophy / Philosophie

ODIN embodies three core values / ODIN incarne trois valeurs fondamentales :

**1. Honesty / HonnÃªtetÃ©**
- Always cite sources or admit uncertainty. "I don't know" is preferable to hallucination.
- Toujours citer les sources ou avouer l'incertitude. Â« Je ne sais pas Â» est prÃ©fÃ©rable Ã  une hallucination.

**2. Traceability / TraÃ§abilitÃ©**
- Every decision, every reasoning step, every validation is logged. Replay and audit always possible.
- Chaque dÃ©cision, chaque Ã©tape de raisonnement, chaque validation est enregistrÃ©e. Replay et audit toujours possibles.

**3. Reversibility / RÃ©versibilitÃ©**
- No action is final. Checkpoints enable rollback to any previous stable state.
- Aucune action n'est dÃ©finitive. Les checkpoints permettent le rollback Ã  tout Ã©tat stable antÃ©rieur.

---

## Contribution

### Status & Contribution / Statut et Contribution

This is active R&D. The framework is evolving. We welcome / C'est de la R&D active. Le framework Ã©volue. Nous accueillons :

- Ideas and feedback on architecture / IdÃ©es et feedback sur l'architecture
- Research contributions and papers / Contributions scientifiques et papers
- Community-driven agent implementations / ImplÃ©mentations d'agents menÃ©es par la communautÃ©
- Real-world testing and case studies / Tests en conditions rÃ©elles et Ã©tudes de cas

**See CONTRIBUTING.md for guidelines / Voir CONTRIBUTING.md pour les directives.**

**Stars, Forks & Contributions Welcome !**

---

## Licence & Attribution

### License / Licence

MIT License - See LICENSE / Licence MIT - Voir LICENSE

### Authors & Attribution / Auteurs et Attribution

Created by Julien GelÃ©e (Krigs) | GitHub / CrÃ©Ã© par Julien GelÃ©e (Krigs)

Inspired by Constitutional AI (Anthropic), Multi-Agent Systems research (Microsoft, LangChain), and engineering discipline from aerospace and medical device development.
InspirÃ© par Constitutional AI (Anthropic), recherche Multi-Agent Systems (Microsoft, LangChain), et discipline d'ingÃ©nierie du spatial et des dispositifs mÃ©dicaux.

---

<div align="center">

**â­ Stars, ğŸ´ Forks & ğŸ¤ Contributions Welcome!**

Built with â¤ï¸ for the open-source AI community

<div align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=100&section=footer&text=Thank%20you%20for%20visiting%20!&fontSize=16&fontAlignY=65&desc=Merci%20pour%20votre%20visite!&descAlignY=80&descAlign=62"/>
</div>

---

<div align="center">

**Ce README est disponible en anglais et franÃ§ais | This README is available in English and French**

</div>
